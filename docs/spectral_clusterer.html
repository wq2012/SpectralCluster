<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>spectralcluster.spectral_clusterer API documentation</title>
<meta name="description" content="A spectral clusterer class to perform clustering." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>spectralcluster.spectral_clusterer</code></h1>
</header>
<section id="section-intro">
<p>A spectral clusterer class to perform clustering.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;A spectral clusterer class to perform clustering.&#34;&#34;&#34;

import numpy as np
from sklearn.cluster import AgglomerativeClustering
from spectralcluster import constraint
from spectralcluster import custom_distance_kmeans
from spectralcluster import fallback_clusterer
from spectralcluster import laplacian
from spectralcluster import refinement
from spectralcluster import utils

RefinementName = refinement.RefinementName
LaplacianType = laplacian.LaplacianType
ConstraintName = constraint.ConstraintName
EigenGapType = utils.EigenGapType


class SpectralClusterer:
  &#34;&#34;&#34;Spectral clustering class.&#34;&#34;&#34;

  def __init__(self,
               min_clusters=None,
               max_clusters=None,
               refinement_options=None,
               autotune=None,
               fallback_options=None,
               laplacian_type=None,
               stop_eigenvalue=1e-2,
               row_wise_renorm=False,
               custom_dist=&#34;cosine&#34;,
               max_iter=300,
               constraint_options=None,
               eigengap_type=EigenGapType.Ratio,
               max_spectral_size=None,
               affinity_function=utils.compute_affinity_matrix,
               post_eigen_cluster_function=custom_distance_kmeans.run_kmeans):
    &#34;&#34;&#34;Constructor of the clusterer.

    Args:
      min_clusters: minimal number of clusters allowed (only effective if not
        None)
      max_clusters: maximal number of clusters allowed (only effective if not
        None), can be used together with min_clusters to fix the number of
        clusters
      refinement_options: a RefinementOptions object that contains refinement
        arguments for the affinity matrix. If None, we will not refine
      autotune: an AutoTune object to automatically search p_percentile
      fallback_options: a FallbackOptions object to indicate when to run
        fallback clusterer instead of spectral clusterer
      laplacian_type: a LaplacianType. If None, we do not use a laplacian matrix
      stop_eigenvalue: when computing the number of clusters using Eigen Gap, we
        do not look at eigen values smaller than this value
      row_wise_renorm: if True, perform row-wise re-normalization on the
        spectral embeddings
      custom_dist: str or callable. custom distance measure for k-means. If a
        string, &#34;cosine&#34;, &#34;euclidean&#34;, &#34;mahalanobis&#34;, or any other distance
        functions defined in scipy.spatial.distance can be used
      max_iter: the maximum number of iterations for the custom k-means
      constraint_options: a ConstraintOptions object that contains constraint
        arguments
      eigengap_type: the type of the eigengap computation
      max_spectral_size: the maximal size of input to the spectral clustering
        algorithm. If this is set, and the actual input size is larger than
        this value, then we are going to first use hierarchical clustering
        to reduce the input size to this number. This can significantly reduce
        the computational cost for steps like Laplacian matrix and eigen
        decomposition. However, please note that this may degrade the quality
        of the final clustering results
      affinity_function: a function to compute the affinity matrix from the
        embeddings. This defaults to (cos(x,y)+1)/2
      post_eigen_cluster_function: a function to cluster the spectral embeddings
        after the eigenvalue computations. This function must have the same
        signature as custom_distance_kmeans.run_kmeans
    &#34;&#34;&#34;
    self.min_clusters = min_clusters
    self.max_clusters = max_clusters
    if not refinement_options:
      self.refinement_options = refinement.RefinementOptions()
    else:
      self.refinement_options = refinement_options
    self.autotune = autotune
    if not fallback_options:
      self.fallback_options = fallback_clusterer.FallbackOptions()
    else:
      self.fallback_options = fallback_options
    self.laplacian_type = laplacian_type
    self.row_wise_renorm = row_wise_renorm
    self.stop_eigenvalue = stop_eigenvalue
    self.custom_dist = custom_dist
    self.max_iter = max_iter
    self.constraint_options = constraint_options
    self.eigengap_type = eigengap_type
    self.max_spectral_size = max_spectral_size
    self.affinity_function = affinity_function
    self.post_eigen_cluster_function = post_eigen_cluster_function

  def _compute_eigenvectors_ncluster(self, affinity, constraint_matrix=None):
    &#34;&#34;&#34;Perform eigen decomposition and estiamte the number of clusters.

    Perform affinity refinement, eigen decomposition and sort eigenvectors by
    the real part of eigenvalues. Estimate the number of clusters using EigenGap
    principle.

    Args:
      affinity: the affinity matrix of input data
      constraint_matrix: numpy array of shape (n_samples, n_samples). The
        constraint matrix with prior information

    Returns:
      eigenvectors: sorted eigenvectors. numpy array of shape
      (n_samples, n_samples)
      n_clusters: number of clusters as an integer
      max_delta_norm: normalized maximum eigen gap
    &#34;&#34;&#34;
    # Perform refinement operations on the affinity matrix.
    for refinement_name in self.refinement_options.refinement_sequence:
      refinement_operator = self.refinement_options.get_refinement_operator(
          refinement_name)
      affinity = refinement_operator.refine(affinity)

    if (self.constraint_options and
        not self.constraint_options.apply_before_refinement):
      # Perform the constraint operation after refinement
      affinity = self.constraint_options.constraint_operator.adjust_affinity(
          affinity, constraint_matrix)

    if not self.laplacian_type or self.laplacian_type == LaplacianType.Affinity:
      # Perform eigen decomposion.
      (eigenvalues, eigenvectors) = utils.compute_sorted_eigenvectors(affinity)
      # Get number of clusters.
      n_clusters, max_delta_norm = utils.compute_number_of_clusters(
          eigenvalues,
          max_clusters=self.max_clusters,
          stop_eigenvalue=self.stop_eigenvalue,
          eigengap_type=self.eigengap_type,
          descend=True)
    else:
      # Compute Laplacian matrix
      laplacian_norm = laplacian.compute_laplacian(
          affinity, laplacian_type=self.laplacian_type)
      # Perform eigen decomposion. Eigen values are sorted in an ascending
      # order
      (eigenvalues, eigenvectors) = utils.compute_sorted_eigenvectors(
          laplacian_norm, descend=False)
      # Get number of clusters. Eigen values are sorted in an ascending order
      n_clusters, max_delta_norm = utils.compute_number_of_clusters(
          eigenvalues,
          max_clusters=self.max_clusters,
          eigengap_type=self.eigengap_type,
          descend=False)
    return eigenvectors, n_clusters, max_delta_norm

  def _reduce_size_and_predict(self, embeddings):
    &#34;&#34;&#34;Reduce the input size, then run spectral clustering.

    Args:
      embeddings: numpy array of shape (n_samples, n_features)

    Returns:
      labels: numpy array of shape (n_samples,)
    &#34;&#34;&#34;
    # Run AHC on the input to reduce the size.
    # Note that linkage needs to be &#34;complete&#34;, ecause &#34;average&#34; and &#34;single&#34;
    # do not work very well here.
    # Alternatively, we can use &#34;euclidean&#34; and &#34;ward&#34;, but that requires
    # that the inputs are L2 normalized first.
    ahc = AgglomerativeClustering(
        n_clusters=self.max_spectral_size,
        affinity=&#34;cosine&#34;,
        linkage=&#34;complete&#34;)
    ahc_labels = ahc.fit_predict(embeddings)

    # Compute the centroids of the AHC clusters.
    ahc_centroids = []
    for i in range(self.max_spectral_size):
      ahc_cluster_embeddings = embeddings[ahc_labels == i, :]
      ahc_centroids.append(np.mean(ahc_cluster_embeddings, axis=0))
    ahc_centroids = np.stack(ahc_centroids)

    # Run spectral clustering on AHC centroids.
    spectral_labels = self.predict(ahc_centroids)

    # Convert spectral labels to final labels.
    final_labels = np.zeros(ahc_labels.shape)
    for i in range(self.max_spectral_size):
      final_labels[ahc_labels == i] = spectral_labels[i]

    return final_labels

  def predict(self, embeddings, constraint_matrix=None):
    &#34;&#34;&#34;Perform spectral clustering on data embeddings.

    The spectral clustering is performed on an affinity matrix.

    Args:
      embeddings: numpy array of shape (n_samples, n_features)
      constraint_matrix: numpy array of shape (n_samples, n_samples). The
        constraint matrix with prior information

    Returns:
      labels: numpy array of shape (n_samples,)

    Raises:
      TypeError: if embeddings has wrong type
      ValueError: if embeddings has wrong shape
      RuntimeError: if max_spectral_size is set and constraint_matrix is given
    &#34;&#34;&#34;
    num_embeddings = embeddings.shape[0]

    if not isinstance(embeddings, np.ndarray):
      raise TypeError(&#34;embeddings must be a numpy array&#34;)
    if len(embeddings.shape) != 2:
      raise ValueError(&#34;embeddings must be 2-dimensional&#34;)

    # Check whether we need to run fallback clusterer instead.
    if (num_embeddings &lt;
        self.fallback_options.spectral_min_embeddings):
      temp_clusterer = fallback_clusterer.FallbackClusterer(
          self.fallback_options)
      return temp_clusterer.predict(embeddings)

    # Check whether the input size is too big for running spectral clustering.
    if (self.max_spectral_size is not None
        and num_embeddings &gt; self.max_spectral_size):
      if constraint_matrix is not None:
        raise RuntimeError(
            &#34;Cannot handle constraint_matrix when max_spectral_size is set&#34;)
      if (self.max_spectral_size &lt; 2 or
         (self.max_clusters and self.max_spectral_size &lt;= self.max_clusters) or
         (self.min_clusters and self.max_spectral_size &lt;= self.min_clusters)):
        raise ValueError(
            &#34;max_spectral_size should be a relatively big number&#34;)
      return self._reduce_size_and_predict(embeddings)

    # Compute affinity matrix.
    affinity = self.affinity_function(embeddings)

    # Make single-vs-multi cluster(s) decision.
    if self.min_clusters == 1:
      if fallback_clusterer.check_single_cluster(
          self.fallback_options, embeddings, affinity):
        return np.array([0] * num_embeddings)

    # Apply constraint.
    if (self.constraint_options and
        self.constraint_options.apply_before_refinement):
      # Perform the constraint operation before refinement
      affinity = self.constraint_options.constraint_operator.adjust_affinity(
          affinity, constraint_matrix)

    if self.autotune:
      # Use Auto-tuning method to find a good p_percentile.
      if (RefinementName.RowWiseThreshold
          not in self.refinement_options.refinement_sequence):
        raise ValueError(
            &#34;AutoTune is only effective when the refinement sequence&#34;
            &#34;contains RowWiseThreshold&#34;)

      def p_percentile_to_ratio(p_percentile):
        &#34;&#34;&#34;Compute the `ratio` given a `p_percentile` value.&#34;&#34;&#34;
        self.refinement_options.p_percentile = p_percentile
        (eigenvectors, n_clusters,
         max_delta_norm) = self._compute_eigenvectors_ncluster(
             affinity, constraint_matrix)
        ratio = np.sqrt(1 - p_percentile) / max_delta_norm
        return ratio, eigenvectors, n_clusters

      eigenvectors, n_clusters, _ = self.autotune.tune(p_percentile_to_ratio)
    else:
      # Do not use Auto-tune.
      eigenvectors, n_clusters, _ = self._compute_eigenvectors_ncluster(
          affinity, constraint_matrix)

    if self.min_clusters is not None:
      n_clusters = max(n_clusters, self.min_clusters)

    # Get spectral embeddings.
    spectral_embeddings = eigenvectors[:, :n_clusters]

    if self.row_wise_renorm:
      # Perform row wise re-normalization.
      rows_norm = np.linalg.norm(spectral_embeddings, axis=1, ord=2)
      spectral_embeddings = spectral_embeddings / np.reshape(
          rows_norm, (num_embeddings, 1))

    # Run clustering algorithm on spectral embeddings. This defaults
    # to customized K-means.
    labels = self.post_eigen_cluster_function(
        spectral_embeddings=spectral_embeddings,
        n_clusters=n_clusters,
        custom_dist=self.custom_dist,
        max_iter=self.max_iter)
    return labels</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="spectralcluster.spectral_clusterer.SpectralClusterer"><code class="flex name class">
<span>class <span class="ident">SpectralClusterer</span></span>
<span>(</span><span>min_clusters=None, max_clusters=None, refinement_options=None, autotune=None, fallback_options=None, laplacian_type=None, stop_eigenvalue=0.01, row_wise_renorm=False, custom_dist='cosine', max_iter=300, constraint_options=None, eigengap_type=EigenGapType.Ratio, max_spectral_size=None, affinity_function=&lt;function compute_affinity_matrix&gt;, post_eigen_cluster_function=&lt;function run_kmeans&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>Spectral clustering class.</p>
<p>Constructor of the clusterer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>min_clusters</code></strong></dt>
<dd>minimal number of clusters allowed (only effective if not
None)</dd>
<dt><strong><code>max_clusters</code></strong></dt>
<dd>maximal number of clusters allowed (only effective if not
None), can be used together with min_clusters to fix the number of
clusters</dd>
<dt><strong><code>refinement_options</code></strong></dt>
<dd>a RefinementOptions object that contains refinement
arguments for the affinity matrix. If None, we will not refine</dd>
<dt><strong><code>autotune</code></strong></dt>
<dd>an AutoTune object to automatically search p_percentile</dd>
<dt><strong><code>fallback_options</code></strong></dt>
<dd>a FallbackOptions object to indicate when to run
fallback clusterer instead of spectral clusterer</dd>
<dt><strong><code>laplacian_type</code></strong></dt>
<dd>a LaplacianType. If None, we do not use a laplacian matrix</dd>
<dt><strong><code>stop_eigenvalue</code></strong></dt>
<dd>when computing the number of clusters using Eigen Gap, we
do not look at eigen values smaller than this value</dd>
<dt><strong><code>row_wise_renorm</code></strong></dt>
<dd>if True, perform row-wise re-normalization on the
spectral embeddings</dd>
<dt><strong><code>custom_dist</code></strong></dt>
<dd>str or callable. custom distance measure for k-means. If a
string, "cosine", "euclidean", "mahalanobis", or any other distance
functions defined in scipy.spatial.distance can be used</dd>
<dt><strong><code>max_iter</code></strong></dt>
<dd>the maximum number of iterations for the custom k-means</dd>
<dt><strong><code>constraint_options</code></strong></dt>
<dd>a ConstraintOptions object that contains constraint
arguments</dd>
<dt><strong><code>eigengap_type</code></strong></dt>
<dd>the type of the eigengap computation</dd>
<dt><strong><code>max_spectral_size</code></strong></dt>
<dd>the maximal size of input to the spectral clustering
algorithm. If this is set, and the actual input size is larger than
this value, then we are going to first use hierarchical clustering
to reduce the input size to this number. This can significantly reduce
the computational cost for steps like Laplacian matrix and eigen
decomposition. However, please note that this may degrade the quality
of the final clustering results</dd>
<dt><strong><code>affinity_function</code></strong></dt>
<dd>a function to compute the affinity matrix from the
embeddings. This defaults to (cos(x,y)+1)/2</dd>
<dt><strong><code>post_eigen_cluster_function</code></strong></dt>
<dd>a function to cluster the spectral embeddings
after the eigenvalue computations. This function must have the same
signature as custom_distance_kmeans.run_kmeans</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SpectralClusterer:
  &#34;&#34;&#34;Spectral clustering class.&#34;&#34;&#34;

  def __init__(self,
               min_clusters=None,
               max_clusters=None,
               refinement_options=None,
               autotune=None,
               fallback_options=None,
               laplacian_type=None,
               stop_eigenvalue=1e-2,
               row_wise_renorm=False,
               custom_dist=&#34;cosine&#34;,
               max_iter=300,
               constraint_options=None,
               eigengap_type=EigenGapType.Ratio,
               max_spectral_size=None,
               affinity_function=utils.compute_affinity_matrix,
               post_eigen_cluster_function=custom_distance_kmeans.run_kmeans):
    &#34;&#34;&#34;Constructor of the clusterer.

    Args:
      min_clusters: minimal number of clusters allowed (only effective if not
        None)
      max_clusters: maximal number of clusters allowed (only effective if not
        None), can be used together with min_clusters to fix the number of
        clusters
      refinement_options: a RefinementOptions object that contains refinement
        arguments for the affinity matrix. If None, we will not refine
      autotune: an AutoTune object to automatically search p_percentile
      fallback_options: a FallbackOptions object to indicate when to run
        fallback clusterer instead of spectral clusterer
      laplacian_type: a LaplacianType. If None, we do not use a laplacian matrix
      stop_eigenvalue: when computing the number of clusters using Eigen Gap, we
        do not look at eigen values smaller than this value
      row_wise_renorm: if True, perform row-wise re-normalization on the
        spectral embeddings
      custom_dist: str or callable. custom distance measure for k-means. If a
        string, &#34;cosine&#34;, &#34;euclidean&#34;, &#34;mahalanobis&#34;, or any other distance
        functions defined in scipy.spatial.distance can be used
      max_iter: the maximum number of iterations for the custom k-means
      constraint_options: a ConstraintOptions object that contains constraint
        arguments
      eigengap_type: the type of the eigengap computation
      max_spectral_size: the maximal size of input to the spectral clustering
        algorithm. If this is set, and the actual input size is larger than
        this value, then we are going to first use hierarchical clustering
        to reduce the input size to this number. This can significantly reduce
        the computational cost for steps like Laplacian matrix and eigen
        decomposition. However, please note that this may degrade the quality
        of the final clustering results
      affinity_function: a function to compute the affinity matrix from the
        embeddings. This defaults to (cos(x,y)+1)/2
      post_eigen_cluster_function: a function to cluster the spectral embeddings
        after the eigenvalue computations. This function must have the same
        signature as custom_distance_kmeans.run_kmeans
    &#34;&#34;&#34;
    self.min_clusters = min_clusters
    self.max_clusters = max_clusters
    if not refinement_options:
      self.refinement_options = refinement.RefinementOptions()
    else:
      self.refinement_options = refinement_options
    self.autotune = autotune
    if not fallback_options:
      self.fallback_options = fallback_clusterer.FallbackOptions()
    else:
      self.fallback_options = fallback_options
    self.laplacian_type = laplacian_type
    self.row_wise_renorm = row_wise_renorm
    self.stop_eigenvalue = stop_eigenvalue
    self.custom_dist = custom_dist
    self.max_iter = max_iter
    self.constraint_options = constraint_options
    self.eigengap_type = eigengap_type
    self.max_spectral_size = max_spectral_size
    self.affinity_function = affinity_function
    self.post_eigen_cluster_function = post_eigen_cluster_function

  def _compute_eigenvectors_ncluster(self, affinity, constraint_matrix=None):
    &#34;&#34;&#34;Perform eigen decomposition and estiamte the number of clusters.

    Perform affinity refinement, eigen decomposition and sort eigenvectors by
    the real part of eigenvalues. Estimate the number of clusters using EigenGap
    principle.

    Args:
      affinity: the affinity matrix of input data
      constraint_matrix: numpy array of shape (n_samples, n_samples). The
        constraint matrix with prior information

    Returns:
      eigenvectors: sorted eigenvectors. numpy array of shape
      (n_samples, n_samples)
      n_clusters: number of clusters as an integer
      max_delta_norm: normalized maximum eigen gap
    &#34;&#34;&#34;
    # Perform refinement operations on the affinity matrix.
    for refinement_name in self.refinement_options.refinement_sequence:
      refinement_operator = self.refinement_options.get_refinement_operator(
          refinement_name)
      affinity = refinement_operator.refine(affinity)

    if (self.constraint_options and
        not self.constraint_options.apply_before_refinement):
      # Perform the constraint operation after refinement
      affinity = self.constraint_options.constraint_operator.adjust_affinity(
          affinity, constraint_matrix)

    if not self.laplacian_type or self.laplacian_type == LaplacianType.Affinity:
      # Perform eigen decomposion.
      (eigenvalues, eigenvectors) = utils.compute_sorted_eigenvectors(affinity)
      # Get number of clusters.
      n_clusters, max_delta_norm = utils.compute_number_of_clusters(
          eigenvalues,
          max_clusters=self.max_clusters,
          stop_eigenvalue=self.stop_eigenvalue,
          eigengap_type=self.eigengap_type,
          descend=True)
    else:
      # Compute Laplacian matrix
      laplacian_norm = laplacian.compute_laplacian(
          affinity, laplacian_type=self.laplacian_type)
      # Perform eigen decomposion. Eigen values are sorted in an ascending
      # order
      (eigenvalues, eigenvectors) = utils.compute_sorted_eigenvectors(
          laplacian_norm, descend=False)
      # Get number of clusters. Eigen values are sorted in an ascending order
      n_clusters, max_delta_norm = utils.compute_number_of_clusters(
          eigenvalues,
          max_clusters=self.max_clusters,
          eigengap_type=self.eigengap_type,
          descend=False)
    return eigenvectors, n_clusters, max_delta_norm

  def _reduce_size_and_predict(self, embeddings):
    &#34;&#34;&#34;Reduce the input size, then run spectral clustering.

    Args:
      embeddings: numpy array of shape (n_samples, n_features)

    Returns:
      labels: numpy array of shape (n_samples,)
    &#34;&#34;&#34;
    # Run AHC on the input to reduce the size.
    # Note that linkage needs to be &#34;complete&#34;, ecause &#34;average&#34; and &#34;single&#34;
    # do not work very well here.
    # Alternatively, we can use &#34;euclidean&#34; and &#34;ward&#34;, but that requires
    # that the inputs are L2 normalized first.
    ahc = AgglomerativeClustering(
        n_clusters=self.max_spectral_size,
        affinity=&#34;cosine&#34;,
        linkage=&#34;complete&#34;)
    ahc_labels = ahc.fit_predict(embeddings)

    # Compute the centroids of the AHC clusters.
    ahc_centroids = []
    for i in range(self.max_spectral_size):
      ahc_cluster_embeddings = embeddings[ahc_labels == i, :]
      ahc_centroids.append(np.mean(ahc_cluster_embeddings, axis=0))
    ahc_centroids = np.stack(ahc_centroids)

    # Run spectral clustering on AHC centroids.
    spectral_labels = self.predict(ahc_centroids)

    # Convert spectral labels to final labels.
    final_labels = np.zeros(ahc_labels.shape)
    for i in range(self.max_spectral_size):
      final_labels[ahc_labels == i] = spectral_labels[i]

    return final_labels

  def predict(self, embeddings, constraint_matrix=None):
    &#34;&#34;&#34;Perform spectral clustering on data embeddings.

    The spectral clustering is performed on an affinity matrix.

    Args:
      embeddings: numpy array of shape (n_samples, n_features)
      constraint_matrix: numpy array of shape (n_samples, n_samples). The
        constraint matrix with prior information

    Returns:
      labels: numpy array of shape (n_samples,)

    Raises:
      TypeError: if embeddings has wrong type
      ValueError: if embeddings has wrong shape
      RuntimeError: if max_spectral_size is set and constraint_matrix is given
    &#34;&#34;&#34;
    num_embeddings = embeddings.shape[0]

    if not isinstance(embeddings, np.ndarray):
      raise TypeError(&#34;embeddings must be a numpy array&#34;)
    if len(embeddings.shape) != 2:
      raise ValueError(&#34;embeddings must be 2-dimensional&#34;)

    # Check whether we need to run fallback clusterer instead.
    if (num_embeddings &lt;
        self.fallback_options.spectral_min_embeddings):
      temp_clusterer = fallback_clusterer.FallbackClusterer(
          self.fallback_options)
      return temp_clusterer.predict(embeddings)

    # Check whether the input size is too big for running spectral clustering.
    if (self.max_spectral_size is not None
        and num_embeddings &gt; self.max_spectral_size):
      if constraint_matrix is not None:
        raise RuntimeError(
            &#34;Cannot handle constraint_matrix when max_spectral_size is set&#34;)
      if (self.max_spectral_size &lt; 2 or
         (self.max_clusters and self.max_spectral_size &lt;= self.max_clusters) or
         (self.min_clusters and self.max_spectral_size &lt;= self.min_clusters)):
        raise ValueError(
            &#34;max_spectral_size should be a relatively big number&#34;)
      return self._reduce_size_and_predict(embeddings)

    # Compute affinity matrix.
    affinity = self.affinity_function(embeddings)

    # Make single-vs-multi cluster(s) decision.
    if self.min_clusters == 1:
      if fallback_clusterer.check_single_cluster(
          self.fallback_options, embeddings, affinity):
        return np.array([0] * num_embeddings)

    # Apply constraint.
    if (self.constraint_options and
        self.constraint_options.apply_before_refinement):
      # Perform the constraint operation before refinement
      affinity = self.constraint_options.constraint_operator.adjust_affinity(
          affinity, constraint_matrix)

    if self.autotune:
      # Use Auto-tuning method to find a good p_percentile.
      if (RefinementName.RowWiseThreshold
          not in self.refinement_options.refinement_sequence):
        raise ValueError(
            &#34;AutoTune is only effective when the refinement sequence&#34;
            &#34;contains RowWiseThreshold&#34;)

      def p_percentile_to_ratio(p_percentile):
        &#34;&#34;&#34;Compute the `ratio` given a `p_percentile` value.&#34;&#34;&#34;
        self.refinement_options.p_percentile = p_percentile
        (eigenvectors, n_clusters,
         max_delta_norm) = self._compute_eigenvectors_ncluster(
             affinity, constraint_matrix)
        ratio = np.sqrt(1 - p_percentile) / max_delta_norm
        return ratio, eigenvectors, n_clusters

      eigenvectors, n_clusters, _ = self.autotune.tune(p_percentile_to_ratio)
    else:
      # Do not use Auto-tune.
      eigenvectors, n_clusters, _ = self._compute_eigenvectors_ncluster(
          affinity, constraint_matrix)

    if self.min_clusters is not None:
      n_clusters = max(n_clusters, self.min_clusters)

    # Get spectral embeddings.
    spectral_embeddings = eigenvectors[:, :n_clusters]

    if self.row_wise_renorm:
      # Perform row wise re-normalization.
      rows_norm = np.linalg.norm(spectral_embeddings, axis=1, ord=2)
      spectral_embeddings = spectral_embeddings / np.reshape(
          rows_norm, (num_embeddings, 1))

    # Run clustering algorithm on spectral embeddings. This defaults
    # to customized K-means.
    labels = self.post_eigen_cluster_function(
        spectral_embeddings=spectral_embeddings,
        n_clusters=n_clusters,
        custom_dist=self.custom_dist,
        max_iter=self.max_iter)
    return labels</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="spectralcluster.spectral_clusterer.SpectralClusterer.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, embeddings, constraint_matrix=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform spectral clustering on data embeddings.</p>
<p>The spectral clustering is performed on an affinity matrix.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>embeddings</code></strong></dt>
<dd>numpy array of shape (n_samples, n_features)</dd>
<dt><strong><code>constraint_matrix</code></strong></dt>
<dd>numpy array of shape (n_samples, n_samples). The
constraint matrix with prior information</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>labels</code></dt>
<dd>numpy array of shape (n_samples,)</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd>if embeddings has wrong type</dd>
<dt><code>ValueError</code></dt>
<dd>if embeddings has wrong shape</dd>
<dt><code>RuntimeError</code></dt>
<dd>if max_spectral_size is set and constraint_matrix is given</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, embeddings, constraint_matrix=None):
  &#34;&#34;&#34;Perform spectral clustering on data embeddings.

  The spectral clustering is performed on an affinity matrix.

  Args:
    embeddings: numpy array of shape (n_samples, n_features)
    constraint_matrix: numpy array of shape (n_samples, n_samples). The
      constraint matrix with prior information

  Returns:
    labels: numpy array of shape (n_samples,)

  Raises:
    TypeError: if embeddings has wrong type
    ValueError: if embeddings has wrong shape
    RuntimeError: if max_spectral_size is set and constraint_matrix is given
  &#34;&#34;&#34;
  num_embeddings = embeddings.shape[0]

  if not isinstance(embeddings, np.ndarray):
    raise TypeError(&#34;embeddings must be a numpy array&#34;)
  if len(embeddings.shape) != 2:
    raise ValueError(&#34;embeddings must be 2-dimensional&#34;)

  # Check whether we need to run fallback clusterer instead.
  if (num_embeddings &lt;
      self.fallback_options.spectral_min_embeddings):
    temp_clusterer = fallback_clusterer.FallbackClusterer(
        self.fallback_options)
    return temp_clusterer.predict(embeddings)

  # Check whether the input size is too big for running spectral clustering.
  if (self.max_spectral_size is not None
      and num_embeddings &gt; self.max_spectral_size):
    if constraint_matrix is not None:
      raise RuntimeError(
          &#34;Cannot handle constraint_matrix when max_spectral_size is set&#34;)
    if (self.max_spectral_size &lt; 2 or
       (self.max_clusters and self.max_spectral_size &lt;= self.max_clusters) or
       (self.min_clusters and self.max_spectral_size &lt;= self.min_clusters)):
      raise ValueError(
          &#34;max_spectral_size should be a relatively big number&#34;)
    return self._reduce_size_and_predict(embeddings)

  # Compute affinity matrix.
  affinity = self.affinity_function(embeddings)

  # Make single-vs-multi cluster(s) decision.
  if self.min_clusters == 1:
    if fallback_clusterer.check_single_cluster(
        self.fallback_options, embeddings, affinity):
      return np.array([0] * num_embeddings)

  # Apply constraint.
  if (self.constraint_options and
      self.constraint_options.apply_before_refinement):
    # Perform the constraint operation before refinement
    affinity = self.constraint_options.constraint_operator.adjust_affinity(
        affinity, constraint_matrix)

  if self.autotune:
    # Use Auto-tuning method to find a good p_percentile.
    if (RefinementName.RowWiseThreshold
        not in self.refinement_options.refinement_sequence):
      raise ValueError(
          &#34;AutoTune is only effective when the refinement sequence&#34;
          &#34;contains RowWiseThreshold&#34;)

    def p_percentile_to_ratio(p_percentile):
      &#34;&#34;&#34;Compute the `ratio` given a `p_percentile` value.&#34;&#34;&#34;
      self.refinement_options.p_percentile = p_percentile
      (eigenvectors, n_clusters,
       max_delta_norm) = self._compute_eigenvectors_ncluster(
           affinity, constraint_matrix)
      ratio = np.sqrt(1 - p_percentile) / max_delta_norm
      return ratio, eigenvectors, n_clusters

    eigenvectors, n_clusters, _ = self.autotune.tune(p_percentile_to_ratio)
  else:
    # Do not use Auto-tune.
    eigenvectors, n_clusters, _ = self._compute_eigenvectors_ncluster(
        affinity, constraint_matrix)

  if self.min_clusters is not None:
    n_clusters = max(n_clusters, self.min_clusters)

  # Get spectral embeddings.
  spectral_embeddings = eigenvectors[:, :n_clusters]

  if self.row_wise_renorm:
    # Perform row wise re-normalization.
    rows_norm = np.linalg.norm(spectral_embeddings, axis=1, ord=2)
    spectral_embeddings = spectral_embeddings / np.reshape(
        rows_norm, (num_embeddings, 1))

  # Run clustering algorithm on spectral embeddings. This defaults
  # to customized K-means.
  labels = self.post_eigen_cluster_function(
      spectral_embeddings=spectral_embeddings,
      n_clusters=n_clusters,
      custom_dist=self.custom_dist,
      max_iter=self.max_iter)
  return labels</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="spectralcluster" href="index.html">spectralcluster</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="spectralcluster.spectral_clusterer.SpectralClusterer" href="#spectralcluster.spectral_clusterer.SpectralClusterer">SpectralClusterer</a></code></h4>
<ul class="">
<li><code><a title="spectralcluster.spectral_clusterer.SpectralClusterer.predict" href="#spectralcluster.spectral_clusterer.SpectralClusterer.predict">predict</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>